{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44de391b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Data Preprocessing Pipeline for Hospital Readmission Prediction\n",
    "# This script handles data cleaning, feature engineering, and bias detection\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class DataPreprocessor:\n",
    "    \"\"\"\n",
    "    A class to handle all data preprocessing steps for hospital readmission prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.scaler = StandardScaler()\n",
    "        self.imputer = SimpleImputer(strategy='median')\n",
    "        \n",
    "    def clean_data(self, df):\n",
    "        \"\"\"\n",
    "        Clean the raw data by handling errors and inconsistencies\n",
    "        \"\"\"\n",
    "        print(\"Step 1: Cleaning raw data...\")\n",
    "        \n",
    "        # Make a copy to avoid modifying original data\n",
    "        cleaned_df = df.copy()\n",
    "        \n",
    "        # Remove duplicate records\n",
    "        initial_size = len(cleaned_df)\n",
    "        cleaned_df = cleaned_df.drop_duplicates()\n",
    "        duplicates_removed = initial_size - len(cleaned_df)\n",
    "        print(f\"  - Removed {duplicates_removed} duplicate records\")\n",
    "        \n",
    "        # Fix obvious data errors\n",
    "        # Age should be between 0 and 120\n",
    "        age_errors = (cleaned_df['age'] < 0) | (cleaned_df['age'] > 120)\n",
    "        if age_errors.sum() > 0:\n",
    "            print(f\"  - Found {age_errors.sum()} age errors, fixing...\")\n",
    "            cleaned_df.loc[age_errors, 'age'] = cleaned_df['age'].median()\n",
    "        \n",
    "        # Length of stay should be positive\n",
    "        los_errors = cleaned_df['length_of_stay'] <= 0\n",
    "        if los_errors.sum() > 0:\n",
    "            print(f\"  - Found {los_errors.sum()} length of stay errors, fixing...\")\n",
    "            cleaned_df.loc[los_errors, 'length_of_stay'] = cleaned_df['length_of_stay'].median()\n",
    "        \n",
    "        # Number of medications should be non-negative\n",
    "        med_errors = cleaned_df['num_medications'] < 0\n",
    "        if med_errors.sum() > 0:\n",
    "            print(f\"  - Found {med_errors.sum()} medication count errors, fixing...\")\n",
    "            cleaned_df.loc[med_errors, 'num_medications'] = 0\n",
    "        \n",
    "        # Standardize text fields\n",
    "        cleaned_df['gender'] = cleaned_df['gender'].str.upper()\n",
    "        cleaned_df['insurance_type'] = cleaned_df['insurance_type'].str.replace('_', ' ').str.title()\n",
    "        \n",
    "        print(f\"  - Data cleaning complete. Final size: {len(cleaned_df)} records\")\n",
    "        return cleaned_df\n",
    "    \n",
    "    def handle_missing_values(self, df):\n",
    "        \"\"\"\n",
    "        Handle missing values in the dataset\n",
    "        \"\"\"\n",
    "        print(\"Step 2: Handling missing values...\")\n",
    "        \n",
    "        # Check for missing values\n",
    "        missing_counts = df.isnull().sum()\n",
    "        missing_percent = (missing_counts / len(df)) * 100\n",
    "        \n",
    "        missing_info = pd.DataFrame({\n",
    "            'Missing Count': missing_counts,\n",
    "            'Missing Percent': missing_percent\n",
    "        })\n",
    "        \n",
    "        print(\"  Missing values summary:\")\n",
    "        print(missing_info[missing_info['Missing Count'] > 0])\n",
    "        \n",
    "        # Handle missing values based on column type\n",
    "        processed_df = df.copy()\n",
    "        \n",
    "        # For numerical columns, use median imputation\n",
    "        numerical_cols = ['age', 'length_of_stay', 'num_medications', 'chronic_conditions', \n",
    "                         'previous_admissions', 'distance_from_hospital']\n",
    "        \n",
    "        for col in numerical_cols:\n",
    "            if processed_df[col].isnull().sum() > 0:\n",
    "                median_value = processed_df[col].median()\n",
    "                processed_df[col].fillna(median_value, inplace=True)\n",
    "                print(f\"  - Filled {col} missing values with median: {median_value:.2f}\")\n",
    "        \n",
    "        # For categorical columns, use mode imputation\n",
    "        categorical_cols = ['gender', 'insurance_type', 'discharge_destination']\n",
    "        \n",
    "        for col in categorical_cols:\n",
    "            if processed_df[col].isnull().sum() > 0:\n",
    "                mode_value = processed_df[col].mode()[0]\n",
    "                processed_df[col].fillna(mode_value, inplace=True)\n",
    "                print(f\"  - Filled {col} missing values with mode: {mode_value}\")\n",
    "        \n",
    "        return processed_df\n",
    "    \n",
    "    def feature_engineering(self, df):\n",
    "        \"\"\"\n",
    "        Create new features from existing data\n",
    "        \"\"\"\n",
    "        print(\"Step 3: Engineering new features...\")\n",
    "        \n",
    "        engineered_df = df.copy()\n",
    "        \n",
    "        # Create polypharmacy flag (taking more than 5 medications)\n",
    "        engineered_df['polypharmacy'] = (engineered_df['num_medications'] > 5).astype(int)\n",
    "        print(\"  - Created polypharmacy flag (>5 medications)\")\n",
    "        \n",
    "        # Create elderly flag (age > 75)\n",
    "        engineered_df['elderly'] = (engineered_df['age'] > 75).astype(int)\n",
    "        print(\"  - Created elderly flag (>75 years)\")\n",
    "        \n",
    "        # Create frequent admissions flag (>2 previous admissions)\n",
    "        engineered_df['frequent_admissions'] = (engineered_df['previous_admissions'] > 2).astype(int)\n",
    "        print(\"  - Created frequent admissions flag (>2 previous)\")\n",
    "        \n",
    "        # Create long stay flag (>7 days)\n",
    "        engineered_df['long_stay'] = (engineered_df['length_of_stay'] > 7).astype(int)\n",
    "        print(\"  - Created long stay flag (>7 days)\")\n",
    "        \n",
    "        # Create high-risk discharge flag (not going home)\n",
    "        engineered_df['high_risk_discharge'] = (engineered_df['discharge_destination'] != 'Home').astype(int)\n",
    "        print(\"  - Created high-risk discharge flag (not home)\")\n",
    "        \n",
    "        # Create distance category (far from hospital)\n",
    "        engineered_df['far_from_hospital'] = (engineered_df['distance_from_hospital'] > 20).astype(int)\n",
    "        print(\"  - Created far from hospital flag (>20 miles)\")\n",
    "        \n",
    "        # Create comorbidity burden score\n",
    "        engineered_df['comorbidity_burden'] = (\n",
    "            engineered_df['chronic_conditions'] * 0.3 +\n",
    "            engineered_df['num_medications'] * 0.1 +\n",
    "            engineered_df['age'] * 0.01\n",
    "        )\n",
    "        print(\"  - Created comorbidity burden score\")\n",
    "        \n",
    "        return engineered_df\n",
    "    \n",
    "    def encode_categorical_variables(self, df):\n",
    "        \"\"\"\n",
    "        Encode categorical variables for machine learning\n",
    "        \"\"\"\n",
    "        print(\"Step 4: Encoding categorical variables...\")\n",
    "        \n",
    "        encoded_df = df.copy()\n",
    "        categorical_columns = ['gender', 'insurance_type', 'discharge_destination']\n",
    "        \n",
    "        for col in categorical_columns:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "            \n",
    "            encoded_df[f'{col}_encoded'] = self.label_encoders[col].fit_transform(encoded_df[col])\n",
    "            print(f\"  - Encoded {col}: {dict(zip(self.label_encoders[col].classes_, self.label_encoders[col].transform(self.label_encoders[col].classes_)))}\")\n",
    "        \n",
    "        return encoded_df\n",
    "    \n",
    "    def detect_bias(self, df):\n",
    "        \"\"\"\n",
    "        Detect potential bias in the dataset\n",
    "        \"\"\"\n",
    "        print(\"Step 5: Detecting potential bias...\")\n",
    "        \n",
    "        # Check readmission rates by demographic groups\n",
    "        bias_report = {}\n",
    "        \n",
    "        # Gender bias\n",
    "        gender_bias = df.groupby('gender')['readmitted_30_days'].agg(['count', 'mean'])\n",
    "        bias_report['gender'] = gender_bias\n",
    "        print(\"  Gender bias analysis:\")\n",
    "        print(gender_bias)\n",
    "        \n",
    "        # Insurance bias\n",
    "        insurance_bias = df.groupby('insurance_type')['readmitted_30_days'].agg(['count', 'mean'])\n",
    "        bias_report['insurance'] = insurance_bias\n",
    "        print(\"\\n  Insurance bias analysis:\")\n",
    "        print(insurance_bias)\n",
    "        \n",
    "        # Age group bias\n",
    "        df['age_group'] = pd.cut(df['age'], bins=[0, 50, 65, 80, 120], labels=['<50', '50-65', '65-80', '>80'])\n",
    "        age_bias = df.groupby('age_group')['readmitted_30_days'].agg(['count', 'mean'])\n",
    "        bias_report['age_group'] = age_bias\n",
    "        print(\"\\n  Age group bias analysis:\")\n",
    "        print(age_bias)\n",
    "        \n",
    "        # Statistical significance test for bias\n",
    "        from scipy.stats import chi2_contingency\n",
    "        \n",
    "        # Test for gender bias\n",
    "        gender_crosstab = pd.crosstab(df['gender'], df['readmitted_30_days'])\n",
    "        chi2_gender, p_gender = chi2_contingency(gender_crosstab)[:2]\n",
    "        print(f\"\\n  Gender bias test: Chi2={chi2_gender:.3f}, p-value={p_gender:.3f}\")\n",
    "        \n",
    "        # Test for insurance bias\n",
    "        insurance_crosstab = pd.crosstab(df['insurance_type'], df['readmitted_30_days'])\n",
    "        chi2_insurance, p_insurance = chi2_contingency(insurance_crosstab)[:2]\n",
    "        print(f\"  Insurance bias test: Chi2={chi2_insurance:.3f}, p-value={p_insurance:.3f}\")\n",
    "        \n",
    "        return bias_report\n",
    "    \n",
    "    def create_visualizations(self, df):\n",
    "        \"\"\"\n",
    "        Create visualizations to understand the data better\n",
    "        \"\"\"\n",
    "        print(\"Step 6: Creating data visualizations...\")\n",
    "        \n",
    "        # Set up the plotting style\n",
    "        plt.style.use('default')\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        \n",
    "        # 1. Age distribution\n",
    "        axes[0, 0].hist(df['age'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes[0, 0].set_title('Age Distribution')\n",
    "        axes[0, 0].set_xlabel('Age')\n",
    "        axes[0, 0].set_ylabel('Count')\n",
    "        \n",
    "        # 2. Readmission rate by gender\n",
    "        gender_rates = df.groupby('gender')['readmitted_30_days'].mean()\n",
    "        axes[0, 1].bar(gender_rates.index, gender_rates.values, color=['pink', 'lightblue'])\n",
    "        axes[0, 1].set_title('Readmission Rate by Gender')\n",
    "        axes[0, 1].set_ylabel('Readmission Rate')\n",
    "        \n",
    "        # 3. Length of stay distribution\n",
    "        axes[0, 2].hist(df['length_of_stay'], bins=20, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "        axes[0, 2].set_title('Length of Stay Distribution')\n",
    "        axes[0, 2].set_xlabel('Days')\n",
    "        axes[0, 2].set_ylabel('Count')\n",
    "        \n",
    "        # 4. Chronic conditions vs readmission\n",
    "        chronic_rates = df.groupby('chronic_conditions')['readmitted_30_days'].mean()\n",
    "        axes[1, 0].plot(chronic_rates.index, chronic_rates.values, marker='o', color='red')\n",
    "        axes[1, 0].set_title('Readmission Rate by Chronic Conditions')\n",
    "        axes[1, 0].set_xlabel('Number of Chronic Conditions')\n",
    "        axes[1, 0].set_ylabel('Readmission Rate')\n",
    "        \n",
    "        # 5. Insurance type distribution\n",
    "        insurance_counts = df['insurance_type'].value_counts()\n",
    "        axes[1, 1].pie(insurance_counts.values, labels=insurance_counts.index, autopct='%1.1f%%')\n",
    "        axes[1, 1].set_title('Insurance Type Distribution')\n",
    "        \n",
    "        # 6. Correlation heatmap of numerical features\n",
    "        numerical_features = ['age', 'length_of_stay', 'num_medications', 'chronic_conditions', \n",
    "                             'previous_admissions', 'distance_from_hospital', 'readmitted_30_days']\n",
    "        correlation_matrix = df[numerical_features].corr()\n",
    "        \n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "                   ax=axes[1, 2], square=True)\n",
    "        axes[1, 2].set_title('Feature Correlation Matrix')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Additional plot: Readmission rate by multiple factors\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "        \n",
    "        # Create a comprehensive analysis\n",
    "        multi_factor_analysis = df.groupby(['elderly', 'polypharmacy', 'frequent_admissions'])['readmitted_30_days'].mean().reset_index()\n",
    "        multi_factor_analysis['group'] = (\n",
    "            multi_factor_analysis['elderly'].astype(str) + '_' +\n",
    "            multi_factor_analysis['polypharmacy'].astype(str) + '_' +\n",
    "            multi_factor_analysis['frequent_admissions'].astype(str)\n",
    "        )\n",
    "        \n",
    "        bars = ax.bar(range(len(multi_factor_analysis)), multi_factor_analysis['readmitted_30_days'])\n",
    "        ax.set_title('Readmission Rate by Risk Factor Combinations')\n",
    "        ax.set_xlabel('Risk Factor Combinations\\n(Elderly_Polypharmacy_FrequentAdmissions)')\n",
    "        ax.set_ylabel('Readmission Rate')\n",
    "        ax.set_xticks(range(len(multi_factor_analysis)))\n",
    "        ax.set_xticklabels(multi_factor_analysis['group'], rotation=45)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b86fd69",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "The following steps demonstrate how to train a Random Forest model for hospital readmission prediction and evaluate its performance using precision and recall metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc4aa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Model Training and Evaluation with Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Assume df is your preprocessed DataFrame and 'readmitted_30_days' is the target\n",
    "# Select features and target\n",
    "target = 'readmitted_30_days'\n",
    "features = [\n",
    "    'age', 'length_of_stay', 'num_medications', 'chronic_conditions',\n",
    "    'previous_admissions', 'distance_from_hospital',\n",
    "    'polypharmacy', 'elderly', 'frequent_admissions', 'long_stay',\n",
    "    'high_risk_discharge', 'far_from_hospital', 'comorbidity_burden',\n",
    "    'gender_encoded', 'insurance_type_encoded', 'discharge_destination_encoded'\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
